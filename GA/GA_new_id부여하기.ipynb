{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'preprocessed' folder already exists at: c:\\Users\\ch.kang\\Documents\\GitHub\\funnel_test\\GA\\..\\\\..\\\\..\\\\Downloads\\preprocessed\n"
     ]
    }
   ],
   "source": [
    "### 현재 작업 디렉토리를 가져오기\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "### downloads 상대경로를 절대경로로 변환\n",
    "relative_path_downloads = r'..\\\\..\\\\..\\\\Downloads'\n",
    "download_path = os.path.join(current_directory, relative_path_downloads)\n",
    "\n",
    "### \"preprocessed\" 상대경로를 절대경로로 변환\n",
    "preprocessed_path = os.path.join(download_path, 'preprocessed')\n",
    "\n",
    "### Check if the \"preprocessed\" folder exists\n",
    "if os.path.exists(preprocessed_path):\n",
    "    print(f\"The 'preprocessed' folder already exists at: {preprocessed_path}\")\n",
    "else:\n",
    "    # \"preprocessed\" 폴더 생성\n",
    "    os.makedirs(preprocessed_path)\n",
    "\n",
    "### ContentsList 상대경로를 절대경로로 변환\n",
    "relative_path_contentslist = r'..\\\\..\\\\..\\\\..\\\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\000_Routine_마이세컨플레이스\\02. IT Platform&Data\\01_콘텐츠성과측정\\001_ContentsList.xlsx'\n",
    "contentslist_path = os.path.join(current_directory, relative_path_contentslist)\n",
    "\n",
    "### DailyRawdata\n",
    "path_dailyrawdata = r'..\\\\..\\\\..\\\\..\\\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\000_Routine_마이세컨플레이스\\02. IT Platform&Data\\01_콘텐츠성과측정\\01_DailyRawdata'\n",
    "\n",
    "\n",
    "### 01_콘텐츠성과측정 상대경로를 절대경로로 변환\n",
    "relative_path_upper_path = r'..\\\\..\\\\..\\\\..\\\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\000_Routine_마이세컨플레이스\\02. IT Platform&Data\\01_콘텐츠성과측정'\n",
    "upper_path = os.path.join(current_directory, relative_path_upper_path)\n",
    "\n",
    "\n",
    "### 02_ConvertedData 상대경로를 절대경로로 변환\n",
    "relative_path_convert_path = r'..\\\\..\\\\..\\\\..\\\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\000_Routine_마이세컨플레이스\\02. IT Platform&Data\\01_콘텐츠성과측정\\02_ConvertedData'\n",
    "convert_path = os.path.join(current_directory, relative_path_convert_path)\n",
    "\n",
    "### new_id 파일 경로 설정\n",
    "mapping_file_path = os.path.join(relative_path_convert_path, 'id_mapping.json')\n",
    "\n",
    "\n",
    "### 03_CombinedData 상대경로를 절대경로로 변환\n",
    "relative_path_combine_path = r'..\\\\..\\\\..\\\\..\\\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\000_Routine_마이세컨플레이스\\02. IT Platform&Data\\01_콘텐츠성과측정\\03_CombinedData'\n",
    "combine_path = os.path.join(current_directory, relative_path_combine_path)\n",
    "\n",
    "\n",
    "### 04_RequestedData 상대경로를 절대경로로 변환\n",
    "relative_path_request_path = r'..\\\\..\\\\..\\\\..\\\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\000_Routine_마이세컨플레이스\\02. IT Platform&Data\\01_콘텐츠성과측정\\04_RequestedData'\n",
    "request_path = os.path.join(current_directory, relative_path_request_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 내의 파일 목록 가져오기\n",
    "file_list = os.listdir(path_dailyrawdata)\n",
    "\n",
    "# 'ga'로 시작하는 전체 파일 필터링\n",
    "ga_files = [file for file in file_list if file.startswith('ga')]\n",
    "\n",
    "# 'ga'로 시작하는 날짜별 파일 필터링: 주석에 유의하자\n",
    "# 날짜 범위\n",
    "# start_date = datetime(2024, 3, 22)\n",
    "# end_date = datetime(2024, 3, 24)\n",
    "#ga_files = [file for file in file_list if file.startswith('ga') and start_date <= datetime.strptime(file.split('_')[1].split('.')[0], '%Y%m%d') <= end_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모든 '아이디' 값들을 저장할 빈 DataFrame 생성\n",
    "all_ids = pd.DataFrame()\n",
    "\n",
    "for file in ga_files:\n",
    "    file_path = os.path.join(path_dailyrawdata, file)\n",
    "    temp_df = pd.read_excel(file_path, dtype=str)\n",
    "    \n",
    "    # 현재 파일에서 '아이디' 열만 추출하여 all_ids에 추가\n",
    "    current_ids = temp_df[['아이디']].copy()  # '아이디' 열만 선택\n",
    "    all_ids = pd.concat([all_ids, current_ids], ignore_index=True)\n",
    "\n",
    "# 중복 제거\n",
    "all_ids_unique = all_ids.drop_duplicates().reset_index(drop=True)\n",
    "all_ids_unique['new_id'] = ['g-' + f'{i:06d}' for i in range(1, len(all_ids_unique) + 1)]\n",
    "all_ids_unique.rename(columns={'아이디': 'pseudo_id'}, inplace=True)\n",
    "# 매핑 정보 파일 경로\n",
    "all_ids_unique.to_csv(mapping_file_path, index=False)\n",
    "# 결과 확인\n",
    "print(all_ids_unique)\n",
    "\n",
    "# 새로운 '아이디' 업데이트 함수\n",
    "def update_id_mapping(existing_mapping_df, new_ids):\n",
    "    if not existing_mapping_df.empty:\n",
    "        max_new_id = max(existing_mapping_df['new_id'].apply(lambda x: int(x.split('-')[1])))+1\n",
    "    else:\n",
    "        max_new_id = 1\n",
    "    new_rows = []\n",
    "    for new_id in new_ids:\n",
    "        if new_id not in existing_mapping_df['pseudo_id'].values:\n",
    "            new_row = {'pseudo_id': new_id, 'new_id': f'g-{max_new_id:06d}'}\n",
    "            new_rows.append(new_row)\n",
    "            max_new_id += 1\n",
    "    if new_rows:\n",
    "        updated_df = pd.concat([existing_mapping_df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    else:\n",
    "        updated_df = existing_mapping_df\n",
    "    return updated_df\n",
    "\n",
    "# 매핑 정보 저장 함수\n",
    "def save_id_mapping(mapping_df, mapping_file_path):\n",
    "    mapping_df.to_csv(mapping_file_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert GA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ga_files:\n",
    "    # 파일 이름과 확장자 분리 및 \"_pivot\" 접미사 추가\n",
    "    file_name, file_ext = os.path.splitext(file)\n",
    "    file_name_with_suffix = file_name + \"_newID\"\n",
    "    new_file_name = file_name_with_suffix + file_ext\n",
    "\n",
    "    # 최종 파일 경로 생성\n",
    "    file_path_convert = os.path.join(convert_path, new_file_name)\n",
    "\n",
    "    # 만약 변환된 파일이 이미 존재한다면, 다음 파일로 넘어감\n",
    "    if os.path.exists(file_path_convert):\n",
    "        print(f\"File already exists: {file_path_convert}\")\n",
    "        continue  # 다음 파일로 넘어감\n",
    "\n",
    "    file_path = os.path.join(path_dailyrawdata, file)  # 파일의 전체 경로 생성\n",
    "    temp_df = pd.read_excel(file_path, dtype=str) # 파일을 데이터프레임으로 읽기\n",
    "\n",
    "    # # new_id 업데이트\n",
    "    # ids = set(temp_df['아이디'].unique())  # 고유 '아이디' 추출\n",
    "    # id_mapping_df = update_id_mapping(id_mapping_df, list(ids))  # 집합을 리스트로 변환하여 함수에 전달\n",
    "    # save_id_mapping(id_mapping_df, mapping_file_path)\n",
    "    # 데이터프레임 로드\n",
    "\n",
    "    # 고유 아이디 매핑 파일 로드\n",
    "    with open(mapping_file_path, 'r') as f:\n",
    "        id_mapping = json.load(f)\n",
    "\n",
    "    # UniqueIDGenerator 클래스\n",
    "    class UniqueIDGenerator:\n",
    "        def __init__(self, id_mapping):\n",
    "            self.id_mapping = id_mapping\n",
    "\n",
    "        def get_unique_id(self, username):\n",
    "            return self.id_mapping.get(username, None)\n",
    "\n",
    "    # UniqueIDGenerator 인스턴스 생성\n",
    "    generator = UniqueIDGenerator(id_mapping)\n",
    "\n",
    "    # 고유 아이디 생성 및 데이터프레임에 추가\n",
    "    temp_df['고유아이디'] = temp_df['아이디'].apply(generator.get_unique_id)\n",
    "    \n",
    "    # 출력, 저장\n",
    "    temp_df.to_excel(file_path_convert)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lablab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
