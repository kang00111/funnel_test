{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01d74892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import shutil\n",
    "import time\n",
    "import pyperclip\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b998eb",
   "metadata": {},
   "source": [
    "# MSP BLOG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f23ea4",
   "metadata": {},
   "source": [
    "# open Chrome -> naver -> login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09872f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "# 불필요한 에러 메시지 없애기\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "\n",
    "# 브라우저 생성\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get('https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com')\n",
    "\n",
    "try:\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '#id')))\n",
    "    time.sleep(3)\n",
    "    nid = 'qli_2018'  # Your ID\n",
    "    npw = '12341234!@'  # Your Password\n",
    "    pyperclip.copy(nid)\n",
    "    browser.find_element(By.CSS_SELECTOR, '#id').send_keys(Keys.CONTROL + 'v')\n",
    "    time.sleep(1)\n",
    "    pyperclip.copy(npw)\n",
    "    browser.find_element(By.CSS_SELECTOR, '#pw').send_keys(Keys.CONTROL + 'v')\n",
    "    pyperclip.copy('')  # Clear clipboard for security\n",
    "    browser.find_element(By.XPATH, '//*[@id=\"log.login\"]').click()\n",
    "    browser.get('https://admin.blog.naver.com/mysecondplace/stat/today')  # Navigate to the target page\n",
    "\n",
    "    # Add your code here to parse the page with BeautifulSoup or perform other actions\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29acfcc4",
   "metadata": {},
   "source": [
    "# article_ids listup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d12abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['20240119', 'contents_url', 'category', 'board1', 'board2', 'title',\n",
       "       'post_start', 'post_end'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'ContentsList.xlsx' 파일 불러오기\n",
    "file_path = r'C:\\Users\\ch.kang\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\003_Project-3\\07_콘텐츠성과측정\\ContentsList.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa46c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 열이 'BH'로 시작하는 행을 선택\n",
    "selected_rows = df[df[df.columns[0]].str.startswith('BM')]\n",
    "\n",
    "# contents_url 열에서 뒤에 12 값을 리스트로 추출\n",
    "article_ids = selected_rows['contents_url'].str[-12:].tolist()\n",
    "\n",
    "# 중복된 값을 제거하고 정렬\n",
    "article_ids = list(set(article_ids))\n",
    "article_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd7e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = ['223203815685',\n",
    " '223208249149',\n",
    " '223209462852']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3eefe8",
   "metadata": {},
   "source": [
    "# crawler for \"views\", \"Acquisition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad55bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize view, total view, total like, and total comment variables\n",
    "view_data = []\n",
    "total_views = []\n",
    "total_likes = []\n",
    "total_comments = []\n",
    "\n",
    "# Create a Selenium WebDriver instance\n",
    "for article_id in article_ids:\n",
    "    # Navigate to the article page\n",
    "    url = f\"https://blog.stat.naver.com/blog/article/{article_id}/referer\"\n",
    "    browser.get(url)\n",
    "\n",
    "    # Click necessary buttons\n",
    "    # 어제 날짜 클릭\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_info_section__1U7kD > div > div:nth-child(1) > div > a\").click()\n",
    "\n",
    "    # Wait until the view counts, like counts, and comment counts are loaded\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_data_section__3AZ-7 > div > div:nth-child(1) > strong\"))\n",
    "    )\n",
    "\n",
    "    # Extract total views, total likes, and total comments using browser.find_element\n",
    "    total_views_element = browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_data_section__3AZ-7 > div > div:nth-child(1) > strong\")\n",
    "    total_likes_element = browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_data_section__3AZ-7 > div > div:nth-child(2) > ul > li:nth-child(1) > strong\")\n",
    "    total_comments_element = browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_data_section__3AZ-7 > div > div:nth-child(2) > ul > li:nth-child(2) > strong\")\n",
    "\n",
    "    # Get the text values from the elements\n",
    "    total_views_text = total_views_element.text.strip()\n",
    "    total_likes_text = total_likes_element.text.strip()\n",
    "    total_comments_text = total_comments_element.text.strip()\n",
    "\n",
    "    # Append the data to the respective lists\n",
    "    total_views.append({'article_id': article_id, 'total_views': total_views_text})\n",
    "    total_likes.append({'article_id': article_id, 'total_likes': total_likes_text})\n",
    "    total_comments.append({'article_id': article_id, 'total_comments': total_comments_text})\n",
    " \n",
    "    #Wait until the \"조회수\" element is present\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#_root > div > div > div:nth-child(2) > div.u_ni_stats_info_wrap > div > div.u_ni_data_section > div > ul > li:nth-child(1) > strong\"))\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    # Extract the text from the element\n",
    "    extracted_text = element.text.strip()\n",
    "    view_data.append({'article_id': article_id, 'views': extracted_text})\n",
    "\n",
    "    # 다운로드 페이지 클릭\n",
    "    time.sleep(3)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_index_section__2a-c1 > a > span:nth-child(2)\").click()\n",
    "\n",
    "    #\"유입분석\" 클릭\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div > div.u_ni_condition_section__1k56B > div > div > div.u_ni_option_group__JMFLr > form > ul:nth-child(2) > li:nth-child(1) > label\").click()\n",
    "    \n",
    "    #\"지표 다운로드\" 클릭\n",
    "    time.sleep(2)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div > div.u_ni_btn_section__3dOcL > a.u_ni_btn_download__KmUvf.u_ni_type_green\").click()\n",
    "    \n",
    "    #Rename and move the downloaded file\n",
    "    time.sleep(5)\n",
    "    latest_file = max([f for f in os.listdir(download_directory) if f.endswith('.xlsx')], key=lambda x: os.path.getctime(os.path.join(download_directory, x)))\n",
    "    yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    new_file_name = f'{article_id}_{yesterday}.xlsx'\n",
    "    os.rename(os.path.join(download_directory, latest_file), os.path.join(download_directory, new_file_name))\n",
    "    desired_folder = r'C:\\Users\\ch.kang\\Documents\\DB_OriginalData_xlsx\\NaverBlogStatistics_MSP'\n",
    "    shutil.move(os.path.join(download_directory, new_file_name), os.path.join(desired_folder, new_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab6f76b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article_id': '223203815685', 'views': '3'},\n",
       " {'article_id': '223208249149', 'views': '7'},\n",
       " {'article_id': '223209462852', 'views': '3'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98b94318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article_id': '223203815685', 'total_views': '67'},\n",
       " {'article_id': '223208249149', 'total_views': '366'},\n",
       " {'article_id': '223209462852', 'total_views': '113'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f5e3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article_id': '223203815685', 'total_likes': '6'},\n",
       " {'article_id': '223208249149', 'total_likes': '5'},\n",
       " {'article_id': '223209462852', 'total_likes': '3'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c1831f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article_id': '223203815685', 'total_comments': '0'},\n",
       " {'article_id': '223208249149', 'total_comments': '0'},\n",
       " {'article_id': '223209462852', 'total_comments': '0'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa1a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884f0863",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=120.0.6099.225)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6FC1E2142+3514994]\n\t(No symbol) [0x00007FF6FBE00CE2]\n\t(No symbol) [0x00007FF6FBCA76AA]\n\t(No symbol) [0x00007FF6FBC80AFD]\n\t(No symbol) [0x00007FF6FBD1CB1B]\n\t(No symbol) [0x00007FF6FBD3218F]\n\t(No symbol) [0x00007FF6FBD15D93]\n\t(No symbol) [0x00007FF6FBCE4BDC]\n\t(No symbol) [0x00007FF6FBCE5C64]\n\tGetHandleVerifier [0x00007FF6FC20E16B+3695259]\n\tGetHandleVerifier [0x00007FF6FC266737+4057191]\n\tGetHandleVerifier [0x00007FF6FC25E4E3+4023827]\n\tGetHandleVerifier [0x00007FF6FBF304F9+689705]\n\t(No symbol) [0x00007FF6FBE0C048]\n\t(No symbol) [0x00007FF6FBE08044]\n\t(No symbol) [0x00007FF6FBE081C9]\n\t(No symbol) [0x00007FF6FBDF88C4]\n\tBaseThreadInitThunk [0x00007FFDBB3F257D+29]\n\tRtlUserThreadStart [0x00007FFDBC06AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#\"지표 다운로드\" 클릭\u001b[39;00m\n\u001b[0;32m     33\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m browser\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#_root > div > div > div > div.u_ni_btn_section__3dOcL > a.u_ni_btn_download__KmUvf.u_ni_type_green\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#Rename and move the downloaded file\u001b[39;00m\n\u001b[0;32m     37\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=120.0.6099.225)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6FC1E2142+3514994]\n\t(No symbol) [0x00007FF6FBE00CE2]\n\t(No symbol) [0x00007FF6FBCA76AA]\n\t(No symbol) [0x00007FF6FBC80AFD]\n\t(No symbol) [0x00007FF6FBD1CB1B]\n\t(No symbol) [0x00007FF6FBD3218F]\n\t(No symbol) [0x00007FF6FBD15D93]\n\t(No symbol) [0x00007FF6FBCE4BDC]\n\t(No symbol) [0x00007FF6FBCE5C64]\n\tGetHandleVerifier [0x00007FF6FC20E16B+3695259]\n\tGetHandleVerifier [0x00007FF6FC266737+4057191]\n\tGetHandleVerifier [0x00007FF6FC25E4E3+4023827]\n\tGetHandleVerifier [0x00007FF6FBF304F9+689705]\n\t(No symbol) [0x00007FF6FBE0C048]\n\t(No symbol) [0x00007FF6FBE08044]\n\t(No symbol) [0x00007FF6FBE081C9]\n\t(No symbol) [0x00007FF6FBDF88C4]\n\tBaseThreadInitThunk [0x00007FFDBB3F257D+29]\n\tRtlUserThreadStart [0x00007FFDBC06AA58+40]\n"
     ]
    }
   ],
   "source": [
    "view_data = []\n",
    "download_directory = r'C:\\Users\\ch.kang\\Downloads'\n",
    "\n",
    "# Create a Selenium WebDriver instance\n",
    "for article_id in article_ids:\n",
    "    # Navigate to the article page\n",
    "    url = f\"https://blog.stat.naver.com/blog/article/{article_id}/referer\"\n",
    "    browser.get(url)\n",
    "\n",
    "    # Click necessary buttons\n",
    "    # 어제 날짜 클릭\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CSS_SELECTOR,\"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_info_section__1U7kD > div > div:nth-child(1) > div > a\").click()\n",
    " \n",
    "    #Wait until the \"조회수\" element is present\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#_root > div > div > div:nth-child(2) > div.u_ni_stats_info_wrap > div > div.u_ni_data_section > div > ul > li:nth-child(1) > strong\"))\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    # Extract the text from the element\n",
    "    extracted_text = element.text.strip()\n",
    "    view_data.append({'article_id': article_id, 'views': extracted_text})\n",
    "\n",
    "    # 다운로드 페이지 클릭\n",
    "    time.sleep(3)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_index_section__2a-c1 > a > span:nth-child(2)\").click()\n",
    "\n",
    "    #\"유입분석\" 클릭\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div > div.u_ni_condition_section__1k56B > div > div > div.u_ni_option_group__JMFLr > form > ul:nth-child(2) > li:nth-child(1) > label\").click()\n",
    "    \n",
    "    #\"지표 다운로드\" 클릭\n",
    "    time.sleep(2)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div > div.u_ni_btn_section__3dOcL > a.u_ni_btn_download__KmUvf.u_ni_type_green\").click()\n",
    "    \n",
    "    #Rename and move the downloaded file\n",
    "    time.sleep(5)\n",
    "    latest_file = max([f for f in os.listdir(download_directory) if f.endswith('.xlsx')], key=lambda x: os.path.getctime(os.path.join(download_directory, x)))\n",
    "    yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    new_file_name = f'{article_id}_{yesterday}.xlsx'\n",
    "    os.rename(os.path.join(download_directory, latest_file), os.path.join(download_directory, new_file_name))\n",
    "    desired_folder = r'C:\\Users\\ch.kang\\Documents\\DB_OriginalData_xlsx\\NaverBlogStatistics_MSP'\n",
    "    shutil.move(os.path.join(download_directory, new_file_name), os.path.join(desired_folder, new_file_name))\n",
    "browser.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445271d7",
   "metadata": {},
   "source": [
    "# Acquisition data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cae52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress openpyxl warning about missing default style\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl.styles.stylesheet\")\n",
    "\n",
    "# Directory containing the Excel files\n",
    "directory_path = r'C:\\Users\\ch.kang\\Documents\\DB_OriginalData_xlsx\\NaverBlogStatistics_MSP'\n",
    "\n",
    "# List of Excel files in the directory\n",
    "excel_files = [file for file in os.listdir(directory_path) if file.endswith('.xlsx') and yesterday in file]\n",
    "\n",
    "# 데이터를 저장할 딕셔너리\n",
    "data_dict = {}\n",
    "\n",
    "# 각 엑셀 파일을 읽어서 데이터를 딕셔너리에 저장\n",
    "for excel_file in excel_files:\n",
    "    # 엑셀 파일의 경로\n",
    "    excel_file_path = os.path.join(directory_path, excel_file)\n",
    "    \n",
    "    # 엑셀 파일 이름에서 14~21자리를 날짜 정보로 추출\n",
    "    date_info = excel_file[13:22]\n",
    "\n",
    "    # Extract article_id from the Excel file name\n",
    "    article_id = excel_file[:12]\n",
    "    \n",
    "    # 엑셀 파일을 데이터프레임으로 읽어오기\n",
    "    df1 = pd.read_excel(excel_file_path)\n",
    "    title = df1.iloc[4, 1]\n",
    "    \n",
    "    # 엑셀 파일을 데이터프레임으로 읽어오기\n",
    "    df = pd.read_excel(excel_file_path, header=8)\n",
    "    \n",
    "    # 데이터프레임을 딕셔너리에 저장, 날짜 정보와 views 정보도 함께 저장\n",
    "    data_dict[article_id] = {\n",
    "    'title': title,\n",
    "    'date_info': date_info,\n",
    "    'views': None,\n",
    "    'acq_path': df['유입경로'].tolist(),\n",
    "    'acq_path_ratio': df['비율'].tolist(),\n",
    "    'acq_path_detail': df['상세유입경로'].tolist(),\n",
    "    'acq_path_detail_ratio': df['비율.1'].tolist()\n",
    "    }\n",
    "\n",
    "# views 정보를 view_data에서 가져와서 딕셔너리에 추가\n",
    "for item in view_data:\n",
    "    article_id = item['article_id']\n",
    "    views = item['views']\n",
    "    key = article_id[:12]  # article_id의 앞 12자리를 key로 사용\n",
    "    \n",
    "    if key in data_dict:\n",
    "        # views 값을 숫자로 변환 (가능한 경우에만)\n",
    "        try:\n",
    "            views_count = int(views)\n",
    "        except (ValueError, TypeError):\n",
    "            views_count = 0  # 변환할 수 없는 경우 views_count를 0으로 설정\n",
    "\n",
    "        data_dict[key]['views'] = views\n",
    "\n",
    "        # acq_path 및 acq_path_detail 결합 (해당 필드가 존재하는 경우에만)\n",
    "        if 'acq_path_ratio' in data_dict[key] and 'acq_path' in data_dict[key]:\n",
    "            new_acq_path = [f\"{path}({ratio}%, {views_count * ratio / 100}건)\" for path, ratio in zip(data_dict[key]['acq_path'], data_dict[key]['acq_path_ratio'])]\n",
    "            data_dict[key]['acq_path'] = new_acq_path\n",
    "\n",
    "        if 'acq_path_detail_ratio' in data_dict[key] and 'acq_path_detail' in data_dict[key]:\n",
    "            new_acq_path_detail = [f\"{path}({ratio}%, {views_count * ratio / 100}건)\" for path, ratio in zip(data_dict[key]['acq_path_detail'], data_dict[key]['acq_path_detail_ratio'])]\n",
    "            data_dict[key]['acq_path_detail'] = new_acq_path_detail\n",
    "\n",
    "# 'acq_path_detail_ratio' 및 'acq_path_ratio' 필드를 모든 data_dict 항목에서 제거\n",
    "for key in data_dict:\n",
    "    if 'acq_path_detail_ratio' in data_dict[key]:\n",
    "        del data_dict[key]['acq_path_detail_ratio']\n",
    "    if 'acq_path_ratio' in data_dict[key]:\n",
    "        del data_dict[key]['acq_path_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be154564",
   "metadata": {},
   "source": [
    "# Output Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# 전치 수행\n",
    "df_msp = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac71a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msp['category'] = 'blog_msp'\n",
    "cols = ['category'] + [col for col in df_msp.columns if col != 'category']\n",
    "df_msp = df_msp[cols]\n",
    "df_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4cc319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20362cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db4bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645dc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3e5d0f1",
   "metadata": {},
   "source": [
    "# HANPRO BLOG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5b8c4",
   "metadata": {},
   "source": [
    "# open Chrome -> naver -> login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "# 불필요한 에러 메시지 없애기\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "\n",
    "# 브라우저 생성\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get('https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com')\n",
    "\n",
    "try:\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '#id')))\n",
    "    time.sleep(3)\n",
    "    nid = 'hanpro911'  # Your ID\n",
    "    npw = 'Zmfflwntlr1!'  # Your Password\n",
    "    pyperclip.copy(nid)\n",
    "    browser.find_element(By.CSS_SELECTOR, '#id').send_keys(Keys.CONTROL + 'v')\n",
    "    time.sleep(1)\n",
    "    pyperclip.copy(npw)\n",
    "    browser.find_element(By.CSS_SELECTOR, '#pw').send_keys(Keys.CONTROL + 'v')\n",
    "    pyperclip.copy('')  # Clear clipboard for security\n",
    "    browser.find_element(By.XPATH, '//*[@id=\"log.login\"]').click()\n",
    "    browser.get('https://admin.blog.naver.com/hanpro911/stat/today')  # Navigate to the target page\n",
    "\n",
    "    # Add your code here to parse the page with BeautifulSoup or perform other actions\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631773be",
   "metadata": {},
   "source": [
    "# article_ids listup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ContentsList.xlsx' 파일 불러오기\n",
    "file_path = r'C:\\Users\\ch.kang\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\003_Project-3\\07_콘텐츠성과측정\\ContentsList.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 열이 'BH'로 시작하는 행을 선택\n",
    "selected_rows = df[df[df.columns[0]].str.startswith('BH')]\n",
    "\n",
    "# contents_url 열에서 뒤에 12 값을 리스트로 추출\n",
    "article_ids = selected_rows['contents_url'].str[-12:].tolist()\n",
    "\n",
    "# 중복된 값을 제거하고 정렬\n",
    "article_ids = list(set(article_ids))\n",
    "article_ids.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a5ced",
   "metadata": {},
   "source": [
    "# crawler for \"views\", \"Acquisition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999bd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_data = []\n",
    "download_directory = r'C:\\Users\\ch.kang\\Downloads'\n",
    "\n",
    "# Create a Selenium WebDriver instance\n",
    "for article_id in article_ids:\n",
    "    # Navigate to the article page\n",
    "    url = f\"https://blog.stat.naver.com/blog/article/{article_id}/referer\"\n",
    "    browser.get(url)\n",
    "\n",
    "    # Click necessary buttons\n",
    "    # 어제 날짜 클릭\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CSS_SELECTOR,\"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_info_section__1U7kD > div > div:nth-child(1) > div > a\").click()\n",
    " \n",
    "    #Wait until the \"조회수\" element is present\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#_root > div > div > div:nth-child(2) > div.u_ni_stats_info_wrap > div > div.u_ni_data_section > div > ul > li:nth-child(1) > strong\"))\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    # Extract the text from the element\n",
    "    extracted_text = element.text.strip()\n",
    "    view_data.append({'article_id': article_id, 'views': extracted_text})\n",
    "\n",
    "    # 다운로드 페이지 클릭\n",
    "    time.sleep(3)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div.u_ni_header_wrap > div > div.u_ni_index_section__2a-c1 > a > span:nth-child(2)\").click()\n",
    "\n",
    "    #\"유입분석\" 클릭\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div > div.u_ni_condition_section__1k56B > div > div > div.u_ni_option_group__JMFLr > form > ul:nth-child(2) > li:nth-child(1) > label\").click()\n",
    "    \n",
    "    #\"지표 다운로드\" 클릭\n",
    "    time.sleep(2)\n",
    "    browser.find_element(By.CSS_SELECTOR, \"#_root > div > div > div > div.u_ni_btn_section__3dOcL > a.u_ni_btn_download__KmUvf.u_ni_type_green\").click()\n",
    "    \n",
    "    #Rename and move the downloaded file\n",
    "    time.sleep(5)\n",
    "    latest_file = max([f for f in os.listdir(download_directory) if f.endswith('.xlsx')], key=lambda x: os.path.getctime(os.path.join(download_directory, x)))\n",
    "    yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    new_file_name = f'{article_id}_{yesterday}.xlsx'\n",
    "    os.rename(os.path.join(download_directory, latest_file), os.path.join(download_directory, new_file_name))\n",
    "    desired_folder = r'C:\\Users\\ch.kang\\Documents\\DB_OriginalData_xlsx\\NaverBlogStatistics_hanpro'\n",
    "    shutil.move(os.path.join(download_directory, new_file_name), os.path.join(desired_folder, new_file_name))\n",
    "browser.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa023f69",
   "metadata": {},
   "source": [
    "# Acquisition data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress openpyxl warning about missing default style\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl.styles.stylesheet\")\n",
    "\n",
    "# Directory containing the Excel files\n",
    "directory_path = r'C:\\Users\\ch.kang\\Documents\\DB_OriginalData_xlsx\\NaverBlogStatistics_hanpro'\n",
    "\n",
    "# List of Excel files in the directory\n",
    "excel_files = [file for file in os.listdir(directory_path) if file.endswith('.xlsx') and yesterday in file]\n",
    "\n",
    "# 데이터를 저장할 딕셔너리\n",
    "data_dict = {}\n",
    "\n",
    "# 각 엑셀 파일을 읽어서 데이터를 딕셔너리에 저장\n",
    "for excel_file in excel_files:\n",
    "    # 엑셀 파일의 경로\n",
    "    excel_file_path = os.path.join(directory_path, excel_file)\n",
    "    \n",
    "    # 엑셀 파일 이름에서 14~21자리를 날짜 정보로 추출\n",
    "    date_info = excel_file[13:22]\n",
    "\n",
    "    # Extract article_id from the Excel file name\n",
    "    article_id = excel_file[:12]\n",
    "    \n",
    "    # 엑셀 파일을 데이터프레임으로 읽어오기\n",
    "    df1 = pd.read_excel(excel_file_path)\n",
    "    title = df1.iloc[4, 1]\n",
    "    \n",
    "    # 엑셀 파일을 데이터프레임으로 읽어오기\n",
    "    df = pd.read_excel(excel_file_path, header=8)\n",
    "    \n",
    "    # 데이터프레임을 딕셔너리에 저장, 날짜 정보와 views 정보도 함께 저장\n",
    "    data_dict[article_id] = {\n",
    "    'title': title,\n",
    "    'date_info': date_info,\n",
    "    'views': None,\n",
    "    'acq_path': df['유입경로'].tolist(),\n",
    "    'acq_path_ratio': df['비율'].tolist(),\n",
    "    'acq_path_detail': df['상세유입경로'].tolist(),\n",
    "    'acq_path_detail_ratio': df['비율.1'].tolist()\n",
    "    }\n",
    "\n",
    "# views 정보를 view_data에서 가져와서 딕셔너리에 추가\n",
    "for item in view_data:\n",
    "    article_id = item['article_id']\n",
    "    views = item['views']\n",
    "    key = article_id[:12]  # article_id의 앞 12자리를 key로 사용\n",
    "    \n",
    "    if key in data_dict:\n",
    "        # views 값을 숫자로 변환 (가능한 경우에만)\n",
    "        try:\n",
    "            views_count = int(views)\n",
    "        except (ValueError, TypeError):\n",
    "            views_count = 0  # 변환할 수 없는 경우 views_count를 0으로 설정\n",
    "\n",
    "        data_dict[key]['views'] = views\n",
    "\n",
    "        # acq_path 및 acq_path_detail 결합 (해당 필드가 존재하는 경우에만)\n",
    "        if 'acq_path_ratio' in data_dict[key] and 'acq_path' in data_dict[key]:\n",
    "            new_acq_path = [f\"{path}({ratio}%, {views_count * ratio / 100}건)\" for path, ratio in zip(data_dict[key]['acq_path'], data_dict[key]['acq_path_ratio'])]\n",
    "            data_dict[key]['acq_path'] = new_acq_path\n",
    "\n",
    "        if 'acq_path_detail_ratio' in data_dict[key] and 'acq_path_detail' in data_dict[key]:\n",
    "            new_acq_path_detail = [f\"{path}({ratio}%, {views_count * ratio / 100}건)\" for path, ratio in zip(data_dict[key]['acq_path_detail'], data_dict[key]['acq_path_detail_ratio'])]\n",
    "            data_dict[key]['acq_path_detail'] = new_acq_path_detail\n",
    "\n",
    "# 'acq_path_detail_ratio' 및 'acq_path_ratio' 필드를 모든 data_dict 항목에서 제거\n",
    "for key in data_dict:\n",
    "    if 'acq_path_detail_ratio' in data_dict[key]:\n",
    "        del data_dict[key]['acq_path_detail_ratio']\n",
    "    if 'acq_path_ratio' in data_dict[key]:\n",
    "        del data_dict[key]['acq_path_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e984e",
   "metadata": {},
   "source": [
    "# Output Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfaa235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# 전치 수행\n",
    "df_han = df.T\n",
    "\n",
    "# blog 구분\n",
    "df_han['category'] = 'blog_hanpro911'\n",
    "cols = ['category'] + [col for col in df_han.columns if col != 'category']\n",
    "df_han = df_han[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_han['category'] = 'blog_hanpro911'\n",
    "cols = ['category'] + [col for col in df_han.columns if col != 'category']\n",
    "df_han = df_han[cols]\n",
    "df_han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_msp, df_han])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get yesterday's date in the format YYYYMMDD\n",
    "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "\n",
    "# Construct the file name\n",
    "file_name = rf\"C:\\Users\\ch.kang\\OneDrive - 클리 주식회사\\문서 - 클리주식회사\\003_Project-3\\07_콘텐츠성과측정\\DailyRawdata\\blog_{yesterday}.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d176eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to the Excel file with the constructed file name\n",
    "df_final.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02e7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
